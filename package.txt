requsets
beautiflsoup4
lxml
pandas
pymongo
useragent robot.txt -> 사용자가 사용중임으로 봇으로 돌리는 프로그램이 아님을 알리는 방법
```
Robots.txt는 웹 페이지의 메인 주소에 '/robots.txt'를 입력하면 확인 할 수 있습니다. 예를 들어 naver의 경우에는 'www.naver.com/robots.txt'를 입력하면 됩니다. 여기서 'User-agent'는 규칙이 적용되는 대상 사용자 에이전트가 누구인지를 말합니다. 'Disallow'와 'Allow'는 각각 크롤링을 금지할 웹 페이지와 허용할 웹 페이지를 뜻합니다. 자세한 규약은 robots.txt 공식 홈페이지(www.robotstxt.org)를 참조해주세요.
```